{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import sys\n",
    "sys.setrecursionlimit(1000)\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/langchain/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from lang_memgpt import (\n",
    "    memgraph\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = os.environ[\"PINECONE_INDEX_NAME\"]\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=\"lang-memgpt\",\n",
    "        dimension=1024, # Replace with your model dimensions\n",
    "        metric=\"cosine\", # Replace with your model metric\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        ) \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "llm_gpt = ChatOpenAI(model=\"gpt-4o\",\n",
    "                  temperature = 0.8,\n",
    "                max_tokens = 4096,\n",
    "                    # stop_sequences = ['</invoke>','</error>'] ,\n",
    "                  streaming=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The class `ChatBedrockConverse` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm_sonnet = ChatBedrockConverse(model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "                                 credentials_profile_name='c35',\n",
    "                  temperature = 0.8,\n",
    "                max_tokens = 4096,\n",
    "                    stop_sequences = ['</invoke>','</error>'] \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "user_id = 'user3'\n",
    "thread_id = str(uuid.uuid4())  # can adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self, user_id: str, thread_id: str):\n",
    "        self.thread_id = thread_id\n",
    "        self.user_id = user_id\n",
    "\n",
    "    async def __call__(self, messages: list) -> str:\n",
    "        chunks = memgraph.astream_events(\n",
    "            input={\n",
    "                \"messages\": messages,\n",
    "            },\n",
    "            config={\n",
    "                \"configurable\": {\n",
    "                    \"llm\":llm_gpt,\n",
    "                    \"user_id\": self.user_id,\n",
    "                    \"thread_id\": self.thread_id,\n",
    "                }\n",
    "            },\n",
    "            version=\"v2\",\n",
    "        )\n",
    "        res = \"\"\n",
    "        flag= True\n",
    "        async for event in chunks:\n",
    "            # print(event)\n",
    "            if event.get(\"event\") == \"on_chat_model_stream\":\n",
    "                tok = event[\"data\"][\"chunk\"].content\n",
    "                if tok:\n",
    "                    if flag:\n",
    "                        print(\"\\n-------answer------:\\n\")\n",
    "                        flag = False\n",
    "                    print (tok,end=\"\")\n",
    "                    res += tok\n",
    "                    # if tok.get('type') == 'tool_use':\n",
    "                    #     continue\n",
    "                    #     # if tok.get('name'):\n",
    "                    #     #     print(tok.get('name'),end=\"\")\n",
    "                    #     # elif tok.get('input'):\n",
    "                    #     #     print(tok.get('input'),end=\"\")\n",
    "                    # elif tok.get('type') == 'text':\n",
    "                    #     if flag:\n",
    "                    #         print(\"\\n-------answer------\")\n",
    "                    #         flag = False\n",
    "                    #     print(tok.get('text'),end=\"\")\n",
    "                    #     res += tok.get('text')\n",
    "        return res\n",
    "    \n",
    "    # def __call__(self, messages: list) -> str:\n",
    "    #     final_state = memgraph.invoke(\n",
    "    #         input={\n",
    "    #             \"messages\": messages,\n",
    "    #         },\n",
    "    #         config={\n",
    "    #             \"configurable\": {\n",
    "    #                 \"llm\":llm_gpt,\n",
    "    #                 \"user_id\": self.user_id,\n",
    "    #                 \"thread_id\": self.thread_id,\n",
    "    #             }\n",
    "    #         }\n",
    "    #     )\n",
    "    #     return final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= []\n",
    "async def handle_chat(input:str,chat:Chat):\n",
    "    messages.append(('user',input))\n",
    "    resp = await chat(messages)\n",
    "    messages.append(('assistant',resp))\n",
    "    return resp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(user_id, thread_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import asyncio\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9091ebcd5a34453faf6fa16bec244e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', description='输入:'), Button(description='发送', style=ButtonStyle())…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 启用嵌套事件循环\n",
    "nest_asyncio.apply()\n",
    "text_input = widgets.Text(description='输入:')\n",
    "send_button = widgets.Button(description='发送')\n",
    "\n",
    "# 创建输出区域\n",
    "output = widgets.Output()\n",
    "\n",
    "# 定义发送按钮点击事件的处理函数\n",
    "def on_send_button_clicked(b):\n",
    "    async def process():\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print('ssss')\n",
    "            response = await handle_chat(text_input.value,chat)\n",
    "            print(response)\n",
    "        text_input.value = ''  \n",
    "    # 使用 asyncio.create_task 来运行异步函数\n",
    "    with output:\n",
    "        asyncio.create_task(process())\n",
    "\n",
    "# 将点击事件与处理函数关联\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# 显示聊天界面\n",
    "display(widgets.VBox([widgets.HBox([text_input, send_button]), output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 你好\n",
      "AI: 你好，老朽乃半仙大师。不知阁下有何指教？\n",
      "Human: 你好\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User likes small animals.']\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "你好，老朽在此。不知阁下有何疑问或烦忧需要解答？命里有时终须有，命里无时莫强求。"
     ]
    }
   ],
   "source": [
    "res = await handle_chat('你好',chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 你好\n",
      "AI: 你好，老朽乃半仙大师。不知阁下有何指教？\n",
      "Human: 你好\n",
      "AI: 你好，老朽在此。不知阁下有何疑问或烦忧需要解答？命里有时终须有，命里无时莫强求。\n",
      "Human: 算一下我的猫\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User likes small animals.']\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "哦，阁下的猫儿是位特别的朋友呢。既然如此，请告知它的姓名及出生年月日吧，老朽好为它算上一算。"
     ]
    }
   ],
   "source": [
    "res = await handle_chat('算一下我的猫',chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'哦，阁下的猫儿是位特别的朋友呢。既然如此，请告知它的姓名及出生年月日吧，老朽好为它算上一算。'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 我有一只猫.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User likes small animals.']\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "你的猫是只非常特别的中国狸花猫，出生在紫禁城里，对吗？你最喜欢和它一起做什么呢？"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"我有一只猫.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 是一只狸花猫，它是出生在故宫里.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User likes small animals.']\n",
      "----save_recall_memory----:User has a Chinese Li Hua cat that was born in the Forbidden City.\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "那真是特别的经历！你的狸花猫能在故宫那样的历史环境中出生，真是非常独特。你平时会给它讲有关故宫的故事吗？"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"是一只狸花猫，它是出生在故宫里.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 稍等，我要接个电话.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User likes small animals.']\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "好的，你忙你的，我在这等你。"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"稍等，我要接个电话.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 回来了，我们继续聊吧，刚才聊到哪儿了？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User likes small animals.']\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "你好，欢迎回来！我们上次聊到你那只可爱的中国狸花猫，它是出生在紫禁城的。你平时喜欢小动物，今天想聊点什么呢？"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"回来了，我们继续聊吧，刚才聊到哪儿了？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 你觉得我的猫的品种怎么样\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User likes small animals.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.']\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "听起来你的猫非常特别，作为一只中国狸花猫，它有着独特的历史和文化背景，尤其是它出生在故宫里，这更增添了它的神秘和高贵。中国狸花猫以其机灵、好动和独立的性格而闻名，同时它们也非常忠诚和友好。你平时喜欢和它一起做些什么呢？"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"你觉得我的猫的品种怎么样\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 我喜欢小动物\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User likes small animals.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.']\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "小动物确实很可爱！你提到过你有一只在紫禁城出生的中国狸花猫。你还有其他的宠物吗？"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"我喜欢小动物\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 呃呃，我今天想看电影\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User likes small animals.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.']\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "哇，好主意！你有特别想看的电影类型吗？例如，动作片、爱情片、科幻片，或者其他类型？还是说你有具体的电影已经在考虑呢？"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"呃呃，我今天想看电影\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 跟我的爱好相关的\n",
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User likes small animals.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.']\n",
      "----search_memory----:User's hobbies\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "目前我知道你喜欢小动物，而且你有一只在紫禁城出生的中华狸花猫。你还有其他的爱好吗？或者你愿意分享更多关于你的小动物的故事吗？"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"跟我的爱好相关的\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 推荐符合我的口味的电影\n",
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User likes small animals.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.']\n",
      "----search_memory----:user's taste in movies\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "由于我目前没有具体关于你电影品味的记忆，可以告诉我你喜欢什么样的电影类型吗？这样我可以更好地为你推荐符合你口味的电影。"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"推荐符合我的口味的电影\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 科幻片\n",
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User likes small animals.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.']\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "你喜欢看科幻片吗？最近有看过什么让你印象深刻的科幻电影吗？"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"科幻片\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----search_memory----:Human: 星际穿越\n",
      "----load_memories----\n",
      "core_memories: []\n",
      "recall_memories: ['User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User has a Chinese Li Hua cat that was born in the Forbidden City.', 'User likes small animals.']\n",
      "\n",
      "-------answer------:\n",
      "\n",
      "《星际穿越》（Interstellar）是一部由克里斯托弗·诺兰执导的科幻电影，于2014年上映。这部电影融合了复杂的科学概念和深刻的情感故事，讲述了一群宇航员穿越虫洞以寻找人类新家园的冒险旅程。\n",
      "\n",
      "你对《星际穿越》有特别的兴趣吗？例如，喜欢它的剧情、特效，还是其中的科学理念？"
     ]
    }
   ],
   "source": [
    "_ = await chat(\"星际穿越\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyautogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
